{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('train.csv')\n",
    "train_labels = full_data.species\n",
    "train = full_data.drop(['species', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Encoding the textual labels categorically and normalize them such that \n",
    "## they contain only values between 0 and n_classes-1. \n",
    "label_encoder = LabelEncoder().fit(train_labels)\n",
    "train_labels = label_encoder.transform(train_labels) \n",
    "num_classes = size(list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Standardising the data to give zero mean\n",
    "## This seems to be very important\n",
    "train = StandardScaler().fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 | train acc: 0.0168, train loss: 4.8136, val acc: 0.0808, val loss: 4.3698\n",
      "epoch   5 | train acc: 0.3737, train loss: 3.2261, val acc: 0.5253, val loss: 2.7887\n",
      "epoch  10 | train acc: 0.7845, train loss: 2.0957, val acc: 0.8384, val loss: 1.5821\n",
      "epoch  15 | train acc: 0.9214, train loss: 1.2410, val acc: 0.8990, val loss: 0.8286\n",
      "epoch  20 | train acc: 0.9618, train loss: 0.6833, val acc: 0.9495, val loss: 0.4229\n",
      "epoch  25 | train acc: 0.9877, train loss: 0.3615, val acc: 0.9596, val loss: 0.2292\n",
      "epoch  30 | train acc: 0.9966, train loss: 0.1889, val acc: 0.9697, val loss: 0.1441\n",
      "epoch  35 | train acc: 0.9989, train loss: 0.0984, val acc: 0.9596, val loss: 0.1179\n",
      "epoch  40 | train acc: 1.0000, train loss: 0.0509, val acc: 0.9798, val loss: 0.0649\n",
      "epoch  45 | train acc: 1.0000, train loss: 0.0266, val acc: 0.9798, val loss: 0.0672\n",
      "epoch  50 | train acc: 0.9989, train loss: 0.0151, val acc: 0.9697, val loss: 0.0687\n",
      "epoch  55 | train acc: 0.9989, train loss: 0.0089, val acc: 0.9798, val loss: 0.0565\n",
      "epoch  60 | train acc: 1.0000, train loss: 0.0042, val acc: 0.9899, val loss: 0.0347\n",
      "epoch  65 | train acc: 1.0000, train loss: 0.0022, val acc: 0.9899, val loss: 0.0613\n",
      "epoch  70 | train acc: 0.9989, train loss: 0.0031, val acc: 0.9899, val loss: 0.0477\n",
      "epoch  75 | train acc: 1.0000, train loss: 0.0006, val acc: 0.9899, val loss: 0.0405\n",
      "epoch  80 | train acc: 1.0000, train loss: 0.0003, val acc: 0.9899, val loss: 0.0290\n",
      "epoch  85 | train acc: 0.9989, train loss: 0.0018, val acc: 0.9899, val loss: 0.0467\n",
      "epoch  90 | train acc: 1.0000, train loss: 0.0001, val acc: 0.9899, val loss: 0.0576\n",
      "epoch  95 | train acc: 1.0000, train loss: 0.0000, val acc: 0.9899, val loss: 0.0352\n",
      "epoch  99 | train acc: 1.0000, train loss: 0.0000, val acc: 0.9899, val loss: 0.0534\n",
      "Resulting Validation Accuracy: 0.9899\n",
      "\n",
      "epoch   0 | train acc: 0.0123, train loss: 4.7796, val acc: 0.0505, val loss: 4.3160\n",
      "epoch   5 | train acc: 0.3715, train loss: 3.2048, val acc: 0.6566, val loss: 2.7593\n",
      "epoch  10 | train acc: 0.7924, train loss: 2.0767, val acc: 0.7980, val loss: 1.5731\n",
      "epoch  15 | train acc: 0.9248, train loss: 1.2340, val acc: 0.9394, val loss: 0.8291\n",
      "epoch  20 | train acc: 0.9708, train loss: 0.6909, val acc: 0.9596, val loss: 0.4124\n",
      "epoch  25 | train acc: 0.9787, train loss: 0.3798, val acc: 0.9798, val loss: 0.2350\n"
     ]
    }
   ],
   "source": [
    "val_acc_list = []\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(train, train_labels):\n",
    "    \n",
    "    X_train, X_valid = train[train_index], train[valid_index]\n",
    "    y_train, y_valid = train_labels[train_index], train_labels[valid_index]\n",
    "    \n",
    "    ## Working with categorical crossentropy function, so converting the labels into \"one-hot\" representation\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_valid = to_categorical(y_valid)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024,input_dim=X_train.shape[1])) # 192\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(num_classes)) # 99\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    total_epochs = 100\n",
    "\n",
    "    def print_results(epoch, logs):\n",
    "        if epoch % 5 == 0 or epoch == total_epochs - 1:\n",
    "            f = 'epoch {:3d} | train acc: {:.4f}, train loss: {:.4f}, val acc: {:.4f}, val loss: {:.4f}'\n",
    "            print(f.format(epoch, logs['acc'], logs['loss'], logs['val_acc'], logs['val_loss']))\n",
    "\n",
    "    cb = keras.callbacks.LambdaCallback(on_epoch_end=print_results)\n",
    "\n",
    "    rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=rms, metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        batch_size=128, \n",
    "                        nb_epoch=total_epochs, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                        verbose=0, \n",
    "                        callbacks=[cb])\n",
    "    val_acc = history.history['val_acc'][-1]\n",
    "    val_acc_list.append(val_acc)\n",
    "    print('Resulting Validation Accuracy: {:.4f}\\n'.format(val_acc))\n",
    "    \n",
    "    plt.plot(history.history['acc'], 'r', history.history['val_acc'], 'b')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Test vs. Validation Accuracy')\n",
    "    \n",
    "print('average accuracy: {:.4f}'.format(sum(val_acc_list) / float(len(val_acc_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Use test set to get actual prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
